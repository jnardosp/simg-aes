{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se lee un archivo npy y se comprime a Zip\n",
    "def npy_to_zip(npy_file,zip_file, cpLv):\n",
    "\n",
    "    with open(npy_file, 'rb') as f:\n",
    "        npy_file = f.read()\n",
    "    \n",
    "    with zipfile.ZipFile(zip_file, 'w', compression=zipfile.ZIP_DEFLATED, compresslevel=cpLv) as zinpy:\n",
    "        zinpy.writestr('npyFile.npy', npy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se lee el hexacimal de zip como enteros de 8 bits y se devuelve un numpy array\n",
    "def zip_to_NPY(zip_file):\n",
    "    with open(zip_file, 'rb') as z:\n",
    "        return np.frombuffer(z.read(), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los dos pasos anteriores se ponen en una funcion\n",
    "def transformation(data):\n",
    "    np.save('mySSDisInPain', data)\n",
    "    npy_to_zip('mySSDisInPain.npy','mySSDinLessPain.zip',9)\n",
    "    return(zip_to_NPY('mySSDinLessPain.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se transforman los datos de un chunck\n",
    "def chunkTransformation(chunk):\n",
    "    return [transformation(item) for item in chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se define el procesado multi nucleo, porque sino es muy lento\n",
    "#Nose si se puede hacer por GPU habria que probar    \n",
    "def dataSeToZipTozipNPY(data):\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    chunk_size = len(data) // num_cores\n",
    "    chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
    "    with multiprocessing.Pool(processes=num_cores) as pool:\n",
    "        modified_arrays = pool.map(chunkTransformation, chunks)\n",
    "    combined_modified_array = [item for sublist in modified_arrays for item in sublist]\n",
    "    return combined_modified_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se normalizan los datos poniendolos del 0 al 1, y se pone padding para que queden \n",
    "#todos del mismo tamaño\n",
    "def normalizeData(vectors):\n",
    "    matriz = []\n",
    "    max_val=0\n",
    "    max_length = max(len(vector) for vector in vectors)\n",
    "    for vector in vectors:\n",
    "        for value in vector:\n",
    "            if(value>=max_val): max_val = value\n",
    "    for vector in vectors:\n",
    "        vector = vector/max_val\n",
    "        matriz.append(np.array(vector.tolist() + [0]*(max_length-len(vector))))\n",
    "    return np.array(matriz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion del dataSet\n",
    "def randomDataSetGenerate(sample_size: int, pol_maxGrade: int, fileName: str):\n",
    "    #Note que esta información random está normalizada entre 0 y 1\n",
    "    matrix = np.random.rand(sample_size, pol_maxGrade) \n",
    "    np.save(fileName, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se procesan los datos\n",
    "if __name__ == \"__main__\":\n",
    "    (x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "    np.save('zipDataSet.npy', (normalizeData(dataSeToZipTozipNPY(x_train))))\n",
    "    np.save('zipDataSet.npy', (normalizeData(dataSeToZipTozipNPY(x_test))))\n",
    "\n",
    "    print(time.time() - start_time) # 4.39 minutos en 12 cores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
